{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망\n",
    "\n",
    "*다층 퍼셉트론\n",
    "\n",
    "-여러 단계를 거쳐 결정을 만들어내는 선형 모델\n",
    "\n",
    "-가중치 만드는 단계가 반복\n",
    "\n",
    "-은닉 단계를 계산하고 최종결과 산출에 가중치합 계산\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "\n",
    "#한글을 출력하기 위한 import\n",
    "#한글 font를 설정해준다.\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname =\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font',family=font_name)\n",
    "\n",
    "import matplotlib as mpl # -깨짐 현상을 해결하기 위햏 matplotlib을 import\n",
    "mpl.rcParams['axes.unicode_minus'] = False # - 깨짐 현상을 해결하기 위한 구문\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "#cancer에 cancer 데이터 저장\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "#cancer데이터 훈련, 테스트 셋으로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data,\n",
    "                                                   cancer.target,\n",
    "                                                   random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도:0.94\n",
      "테스트 세트 정확도:0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#mlp 객체에 MLP모델 적용 및 훈련세트 학습\n",
    "mlp = MLPClassifier(random_state = 42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "#훈련, 테스트 세트 정확도 출력\n",
    "print(\"훈련 세트 정확도:{:.2f}\".format(mlp.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도:{:.2f}\".format(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z-score 표준화\n",
    "\n",
    "#훈련 세트 각 특성의 평균을 계산\n",
    "mean_on_train = X_train.mean(axis=0)\n",
    "\n",
    "#훈련 세트 각 특성의 표준 편차를 계산합니다.\n",
    "std_on_train = X_train.std(axis = 0)\n",
    "\n",
    "#데이터에서 평균을 빼고 표준 편차로 나누면\n",
    "#평균 0, 표준 편차 1인 데이터로 변환됨\n",
    "X_train_scaled = (X_train - mean_on_train) / std_on_train\n",
    "\n",
    "#훈련 데이터 값을 이용해\n",
    "#테스트 세트에도 똑같이 적용\n",
    "X_test_scaled = (X_test - mean_on_train) / std_on_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.991\n",
      "테스트 세트 정확도: 0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12zzz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#데이터 전처리를 한 뒤 \n",
    "#훈련 세트를 학습시킨다.\n",
    "mlp = MLPClassifier(random_state = 0)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "    \n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "#정확도가 데이터 전처리 이전보다 향상되었음을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 1.000\n",
      "테스트 세트 정확도: 0.972\n"
     ]
    }
   ],
   "source": [
    "#max_iter -> 반복횟수 증가\n",
    "#반복횟수 증가로 인해 성능의 향상이 있음\n",
    "mlp = MLPClassifier(max_iter = 1000,random_state = 0)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "    \n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.988\n",
      "테스트 세트 정확도: 0.972\n"
     ]
    }
   ],
   "source": [
    "#alpha 증가 -> 규제강화 \n",
    "#규제 강화에도 성능에 큰 변화는 없다.\n",
    "mlp = MLPClassifier(max_iter = 1000,alpha = 1 , random_state = 0)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "    \n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP(신경망)\n",
    "\n",
    "장점\n",
    "\n",
    "-충분한 시간과 데이터가 있으면 매우 복잡한 모델을 만들어 냄\n",
    "\n",
    "-다른 알고리즘들을 압도하는 성능을 발휘 (음성, 영상, 번역 등)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단점\n",
    "\n",
    "-데이터 전처리에 민감, 이종의 데이터 타입일 경우 잘 안맞음\n",
    "\n",
    "-매개변수 튜닝이 매우 어려움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
